{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Dstereo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin-salazar/computacionGrafica/blob/master/3Dstereo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AK03osnXi3q",
        "colab_type": "text"
      },
      "source": [
        "# Cargar datos para calibrar camara"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFPXtQztJzyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "d0ed1d1f-9a99-44e6-fcee-f0ef27491fd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls '/content/drive/My Drive/3DReconstruction/tableroFotos'"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "20191218_170008.jpg  20191218_170310.jpg  20191218_170701.jpg\n",
            "20191218_170016.jpg  20191218_170316.jpg  20191218_170710.jpg\n",
            "20191218_170021.jpg  20191218_170321.jpg  20191218_170721.jpg\n",
            "20191218_170033.jpg  20191218_170326.jpg  20191218_170728.jpg\n",
            "20191218_170044.jpg  20191218_170405.jpg  20191218_170748.jpg\n",
            "20191218_170048.jpg  20191218_170409.jpg  20191218_170753.jpg\n",
            "20191218_170052.jpg  20191218_170415.jpg  20191218_170757.jpg\n",
            "20191218_170057.jpg  20191218_170422.jpg  20191218_170802.jpg\n",
            "20191218_170101.jpg  20191218_170428.jpg  20191218_170807.jpg\n",
            "20191218_170115.jpg  20191218_170436.jpg  20191218_170811.jpg\n",
            "20191218_170122.jpg  20191218_170437.jpg  20191218_170817.jpg\n",
            "20191218_170135.jpg  20191218_170443.jpg  20191218_170822.jpg\n",
            "20191218_170140.jpg  20191218_170454.jpg  20191218_170829.jpg\n",
            "20191218_170145.jpg  20191218_170458.jpg  20191218_170834.jpg\n",
            "20191218_170153.jpg  20191218_170502.jpg  20191218_170858.jpg\n",
            "20191218_170156.jpg  20191218_170519.jpg  20191218_170902.jpg\n",
            "20191218_170200.jpg  20191218_170526.jpg  20191218_170907.jpg\n",
            "20191218_170206.jpg  20191218_170538.jpg  20191218_170913.jpg\n",
            "20191218_170219.jpg  20191218_170547.jpg  20191218_171039.jpg\n",
            "20191218_170224.jpg  20191218_170553.jpg  20191218_171044.jpg\n",
            "20191218_170230.jpg  20191218_170603.jpg  20191218_171049.jpg\n",
            "20191218_170235.jpg  20191218_170608.jpg  20191218_171058.jpg\n",
            "20191218_170244.jpg  20191218_170614.jpg  20191218_171112.jpg\n",
            "20191218_170251.jpg  20191218_170635.jpg  20191218_171119.jpg\n",
            "20191218_170258.jpg  20191218_170641.jpg\n",
            "20191218_170304.jpg  20191218_170645.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RonT7TK6aoik",
        "colab_type": "text"
      },
      "source": [
        "## Camera Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn5WWrykJy4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH=\"/content/drive/My Drive/3DReconstruction/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIrJSzLam4-",
        "colab_type": "code",
        "outputId": "6c995b2e-0cc4-454b-dc30-463444a7dc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np \n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import PIL.ExifTags\n",
        "import PIL.Image\n",
        "\n",
        "#============================================\n",
        "# Camera calibration\n",
        "#============================================\n",
        "\n",
        "#Define size of chessboard target. \n",
        "\n",
        "chessboard_size = (7,5)\n",
        "\n",
        "#Define arrays to save detected points\n",
        "obj_points = [] #3D points in real world space \n",
        "img_points = [] #3D points in image plane\n",
        "\n",
        "#Prepare grid and points to display\n",
        "\n",
        "objp = np.zeros((np.prod(chessboard_size),3),dtype=np.float32)\n",
        "\n",
        "\n",
        "objp[:,:2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1,2)\n",
        "\n",
        "#read images\n",
        "\n",
        "calibration_paths = glob.glob(PATH+'tableroFotos/*')\n",
        "\n",
        "#Iterate over images to find intrinsic matrix\n",
        "for image_path in tqdm(calibration_paths):\n",
        "\n",
        "\t#Load image\n",
        "\timage = cv2.imread(image_path)\n",
        "\tgray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\tprint(\"Image loaded, Analizying...\")\n",
        "\t#find chessboard corners\n",
        "\tret,corners = cv2.findChessboardCorners(gray_image, chessboard_size, None)\n",
        "\n",
        "\tif ret == True:\n",
        "\t\tprint(\"Chessboard detected!\")\n",
        "\t\tprint(image_path)\n",
        "\t\t#define criteria for subpixel accuracy\n",
        "\t\tcriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\t\t#refine corner location (to subpixel accuracy) based on criteria.\n",
        "\t\tcv2.cornerSubPix(gray_image, corners, (5,5), (-1,-1), criteria)\n",
        "\t\tobj_points.append(objp)\n",
        "\t\timg_points.append(corners)\n",
        "\n",
        "#Calibrate camera\n",
        "ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points,gray_image.shape[::-1], None, None)\n",
        "\n",
        "#Save parameters into numpy file\n",
        "np.save(PATH+'parametrosCamara/ret', ret)\n",
        "np.save(PATH+'parametrosCamara/K', K)\n",
        "np.save(PATH+'parametrosCamara/dist', dist)\n",
        "np.save(PATH+'parametrosCamara/rvecs', rvecs)\n",
        "np.save(PATH+'parametrosCamara/tvecs', tvecs)\n",
        "\n",
        "#Get exif data in order to get focal length. \n",
        "exif_img = PIL.Image.open(calibration_paths[0])\n",
        "\n",
        "exif_data = {\n",
        "\tPIL.ExifTags.TAGS[k]:v\n",
        "\tfor k, v in exif_img._getexif().items()\n",
        "\tif k in PIL.ExifTags.TAGS}\n",
        "\n",
        "#Get focal length in tuple form\n",
        "focal_length_exif = exif_data['FocalLength']\n",
        "\n",
        "#Get focal length in decimal form\n",
        "focal_length = focal_length_exif[0]/focal_length_exif[1]\n",
        "\n",
        "#Save focal length\n",
        "np.save(PATH+'parametrosCamara/FocalLength', focal_length)\n",
        "\n",
        "#Calculate projection error. \n",
        "mean_error = 0\n",
        "for i in range(len(obj_points)):\n",
        "\timg_points2, _ = cv2.projectPoints(obj_points[i],rvecs[i],tvecs[i], K, dist)\n",
        "\terror = cv2.norm(img_points[i], img_points2, cv2.NORM_L2)/len(img_points2)\n",
        "\tmean_error += error\n",
        "\n",
        "total_error = mean_error/len(obj_points)\n",
        "print (total_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/76 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 1/76 [01:18<1:38:08, 78.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/76 [02:32<1:35:03, 77.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 3/76 [04:01<1:38:04, 80.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 4/76 [05:33<1:40:52, 84.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 5/76 [07:07<1:43:01, 87.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 6/76 [08:38<1:42:55, 88.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 7/76 [09:32<1:29:52, 78.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 8/76 [10:40<1:24:53, 74.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 9/76 [11:59<1:25:02, 76.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 10/76 [13:33<1:29:37, 81.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 11/76 [14:46<1:25:31, 78.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 12/76 [15:59<1:22:19, 77.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 13/76 [17:11<1:19:23, 75.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 14/76 [18:08<1:12:27, 70.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 15/76 [18:57<1:04:47, 63.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 16/76 [19:33<55:24, 55.40s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 17/76 [21:04<1:05:04, 66.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 18/76 [22:14<1:04:54, 67.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 19/76 [23:34<1:07:34, 71.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 20/76 [24:47<1:06:50, 71.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 21/76 [26:01<1:06:23, 72.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 22/76 [27:18<1:06:26, 73.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 23/76 [28:16<1:00:53, 68.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 24/76 [29:16<57:24, 66.23s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 25/76 [30:32<58:59, 69.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 26/76 [31:20<52:27, 62.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 27/76 [32:27<52:26, 64.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 28/76 [33:27<50:13, 62.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 29/76 [34:19<46:35, 59.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 30/76 [35:15<44:52, 58.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 31/76 [36:25<46:24, 61.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image loaded, Analizying...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2YCxjd2qVB3",
        "colab_type": "text"
      },
      "source": [
        "## Epipolar Geometry\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOg4t7RNqizO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "img1 = cv.imread(PATH+'reconstruct_this/image1.png',0)  #queryimage # left image\n",
        "img2 = cv.imread(PATH+'reconstruct_this/image1.png',0) #trainimage # right image\n",
        "#sift = cv.SIFT()\n",
        "sift = cv2.xfeatures2d.SURF_create()\n",
        "\n",
        "# find the keypoints and descriptors with SIFT\n",
        "kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "kp2, des2 = sift.detectAndCompute(img2,None)\n",
        "# FLANN parameters\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "search_params = dict(checks=50)\n",
        "flann = cv.FlannBasedMatcher(index_params,search_params)\n",
        "matches = flann.knnMatch(des1,des2,k=2)\n",
        "good = []\n",
        "pts1 = []\n",
        "pts2 = []\n",
        "# ratio test as per Lowe's paper\n",
        "for i,(m,n) in enumerate(matches):\n",
        "    if m.distance < 0.8*n.distance:\n",
        "        good.append(m)\n",
        "        pts2.append(kp2[m.trainIdx].pt)\n",
        "        pts1.append(kp1[m.queryIdx].pt)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT5ThTWf4nxO",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://docs.opencv.org/3.4.4/epipolar.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxHWt9qO440O",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://docs.opencv.org/3.4.4/epiresult.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm6MSAfDfjUa",
        "colab_type": "text"
      },
      "source": [
        "## 3D Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrHRagOefiSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np \n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import PIL.ExifTags\n",
        "import PIL.Image\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "#=====================================\n",
        "# Function declarations\n",
        "#=====================================\n",
        "\n",
        "#Function to create point cloud file\n",
        "def create_output(vertices, colors, filename):\n",
        "\tcolors = colors.reshape(-1,3)\n",
        "\tvertices = np.hstack([vertices.reshape(-1,3),colors])\n",
        "\n",
        "\tply_header = '''ply\n",
        "\t\tformat ascii 1.0\n",
        "\t\telement vertex %(vert_num)d\n",
        "\t\tproperty float x\n",
        "\t\tproperty float y\n",
        "\t\tproperty float z\n",
        "\t\tproperty uchar red\n",
        "\t\tproperty uchar green\n",
        "\t\tproperty uchar blue\n",
        "\t\tend_header\n",
        "\t\t'''\n",
        "\twith open(filename, 'w') as f:\n",
        "\t\tf.write(ply_header %dict(vert_num=len(vertices)))\n",
        "\t\tnp.savetxt(f,vertices,'%f %f %f %d %d %d')\n",
        "\n",
        "#Function that Downsamples image x number (reduce_factor) of times. \n",
        "def downsample_image(image, reduce_factor):\n",
        "\tfor i in range(0,reduce_factor):\n",
        "\t\t#Check if image is color or grayscale\n",
        "\t\tif len(image.shape) > 2:\n",
        "\t\t\trow,col = image.shape[:2]\n",
        "\t\telse:\n",
        "\t\t\trow,col = image.shape\n",
        "\n",
        "\t\timage = cv2.pyrDown(image, dstsize= (col//2, row // 2))\n",
        "\treturn image\n",
        "\n",
        "\n",
        "#=========================================================\n",
        "# Stereo 3D reconstruction \n",
        "#=========================================================\n",
        "\n",
        "#Load camera parameters\n",
        "ret = np.load(PATH+'parametrosCamara/ret.npy')\n",
        "K = np.load(PATH+'parametrosCamara/K.npy')\n",
        "dist = np.load(PATH+'parametrosCamara/dist.npy')\n",
        "\n",
        "#Specify image paths\n",
        "img_path1 = PATH+'stereoFotos/sillaL.jpg'\n",
        "img_path2 = PATH+'stereoFotos/sillaR.jpg'\n",
        "\n",
        "#Load pictures\n",
        "img_1 = cv2.imread(img_path1)\n",
        "img_2 = cv2.imread(img_path2)\n",
        "\n",
        "#Get height and width. Note: It assumes that both pictures are the same size. They HAVE to be same size and height. \n",
        "h,w = img_2.shape[:2]\n",
        "\n",
        "#Get optimal camera matrix for better undistortion \n",
        "new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(K,dist,(w,h),1,(w,h))\n",
        "\n",
        "#Undistort images\n",
        "img_1_undistorted = cv2.undistort(img_1, K, dist, None, new_camera_matrix)\n",
        "img_2_undistorted = cv2.undistort(img_2, K, dist, None, new_camera_matrix)\n",
        "\n",
        "#Downsample each image 3 times (because they're too big)\n",
        "img_1_downsampled = downsample_image(img_1_undistorted,3)\n",
        "img_2_downsampled = downsample_image(img_2_undistorted,3)\n",
        "\n",
        "#cv2.imwrite('undistorted_left.jpg', img_1_downsampled)\n",
        "#cv2.imwrite('undistorted_right.jpg', img_2_downsampled)\n",
        "\n",
        "\n",
        "#Set disparity parameters\n",
        "#Note: disparity range is tuned according to specific parameters obtained through trial and error. \n",
        "win_size = 5\n",
        "min_disp = -1\n",
        "max_disp = 63 #min_disp * 9\n",
        "num_disp = max_disp - min_disp # Needs to be divisible by 16\n",
        "\n",
        "#Create Block matching object. \n",
        "stereo = cv2.StereoSGBM_create(minDisparity= min_disp,\n",
        "\tnumDisparities = num_disp,\n",
        "\tblockSize = 5,\n",
        "\tuniquenessRatio = 5,\n",
        "\tspeckleWindowSize = 5,\n",
        "\tspeckleRange = 5,\n",
        "\tdisp12MaxDiff = 2,\n",
        "\tP1 = 8*3*win_size**2,#8*3*win_size**2,\n",
        "\tP2 =32*3*win_size**2) #32*3*win_size**2)\n",
        "\n",
        "#Compute disparity map\n",
        "print (\"\\nComputing the disparity  map...\")\n",
        "disparity_map = stereo.compute(img_1_downsampled, img_2_downsampled)\n",
        "\n",
        "#Show disparity map before generating 3D cloud to verify that point cloud will be usable. \n",
        "plt.imshow(disparity_map,'gray')\n",
        "plt.show()\n",
        "\n",
        "#Generate  point cloud. \n",
        "print (\"\\nGenerating the 3D map...\")\n",
        "\n",
        "#Get new downsampled width and height \n",
        "h,w = img_2_downsampled.shape[:2]\n",
        "\n",
        "#Load focal length. \n",
        "focal_length = np.load(PATH+'parametrosCamara/FocalLength.npy')\n",
        "\n",
        "#Perspective transformation matrix\n",
        "#This transformation matrix is from the openCV documentation, didn't seem to work for me. \n",
        "Q = np.float32([[1,0,0,-w/2.0],\n",
        "\t\t\t\t[0,-1,0,h/2.0],\n",
        "\t\t\t\t[0,0,0,-focal_length],\n",
        "\t\t\t\t[0,0,1,0]])\n",
        "\n",
        "#This transformation matrix is derived from Prof. Didier Stricker's power point presentation on computer vision. \n",
        "#Link : https://ags.cs.uni-kl.de/fileadmin/inf_ags/3dcv-ws14-15/3DCV_lec01_camera.pdf\n",
        "Q2 = np.float32([[1,0,0,0],\n",
        "\t\t\t\t[0,-1,0,0],\n",
        "\t\t\t\t[0,0,focal_length*0.05,0], #Focal length multiplication obtained experimentally. \n",
        "\t\t\t\t[0,0,0,1]])\n",
        "\n",
        "#Reproject points into 3D\n",
        "points_3D = cv2.reprojectImageTo3D(disparity_map, Q2)\n",
        "#Get color points\n",
        "colors = cv2.cvtColor(img_1_downsampled, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Get rid of points with value 0 (i.e no depth)\n",
        "mask_map = disparity_map > disparity_map.min()\n",
        "\n",
        "#Mask colors and points. \n",
        "output_points = points_3D[mask_map]\n",
        "output_colors = colors[mask_map]\n",
        "\n",
        "#Define name for output file\n",
        "output_file = 'reconstructed.ply'\n",
        "\n",
        "#Generate point cloud \n",
        "print(\"\\n Creating the output file... \\n\")\n",
        "create_output(output_points, output_colors, output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}